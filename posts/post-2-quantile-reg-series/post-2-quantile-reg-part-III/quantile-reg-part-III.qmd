---
title: "Quantile Regressions in Stan: Part III"
author: "Sean Pinkney"
date: last-modified
categories: [stan, quantile]
bibliography: references.bib
draft: false
format:
  html:
    code-fold: true
    code-summary: "Show the code"
---

```{r, message=FALSE, echo=FALSE}
library(cmdstanr)
check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)
register_knitr_engine(override = FALSE)
```

This is part III of the quantile regression series. [Part I](/posts/post-2-quantile-reg-part-I/quantile-reg.qmd) and [part II](/posts/post-2-quantile-reg-part-II/quantile-reg-part-II.qmd) show the Bayesian quantile regression using the asymmetric Laplace distribution, augmented scheme, and score. In this post I'm going to show the multiple quantile regression given in @score, which is a follow up to part II.


# Multiple quantile regression with score

The score method includes the regressors into the objective function as $$
s_\tau(\beta) = \sum_{i=1}^{n} x_i \psi_\tau(y_i - x_i^{\top}\beta).
$$ where $\psi_\tau(u) = \tau - I(u < 0)$.

@score consider the following "working" likelihood 
$$
\mathcal{L}(y \mid x,\, \beta) = C \exp\bigg(-\frac{1}{2n} s_\tau(\beta)^{\top} W s_\tau(\beta)  \bigg),
$$
where $W$ is a $p \times p$ positive definite weight matrix, and C is a constant free of $\beta$. The quadratic form and the given objective function implies that the quantile estimator is maximized at the typical quantile estimate.

The $W$ matrix for multiple quantiles is given as

$$
W = (Q \otimes G )^{-1}, \text{ where } Q = (\min(\tau_i, \tau_j) - \tau_i \tau_j)_{ij}, \; G = \frac{1}{n}\sum_{i=1}^n x_i x_i^{\top}.
$$ 

A nice property of $W$ is that it depends all on user input data so can be constructed outside of the MCMC iterations.

## Score function

The following Stan model implements the multiple $\tau$ code. 

```{cmdstan, eval=TRUE, output.var="multiple_score_qr", class.source = 'fold-show'}
functions{
  matrix kronecker(matrix A, matrix B) {
    matrix[rows(A) * rows(B), cols(A) * cols(B)] C;
    int m = rows(A);
    int n = cols(A);
    int p = rows(B);
    int q = cols(B);
    for (i in 1:m) {
      for (j in 1:n) {
        int row_start = (i - 1) * p + 1;
        int row_end = (i - 1) * p + p;
        int col_start = (j - 1) * q + 1;
        int col_end = (j - 1) * q + q;
        C[row_start:row_end, col_start:col_end] = A[i, j] * B;
      }
    }
   return C;
}
  
  vector q_loss(real q, vector u){
    return (abs(u) + (2 * q - 1) * u);
 }
    
  vector score(vector q, vector y, matrix x, array[] vector beta) {
    int N = num_elements(y);
    int P = num_elements(beta[ , 1]);
    int K = num_elements(q);
    matrix[K, P] out;
      
    for (k in 1:K) {
      out[k] = transpose(transpose(x) * q_loss(q[k], y - x * to_vector(beta[ ,k])));
    }
      
    return to_vector(out);
  }
    
  matrix make_w (matrix x, vector q) {
    int N = rows(x);
    int P = cols(x);
    int m = num_elements(q);
    matrix[m * P, m * P] out;
      
    matrix[m, m] Q;
    matrix[P, P] G = crossprod(x) ;
    
  //  G[1:P, 1] /= log(N);
  //  G[1, 2:P] = transpose(G[2:P, 1]);
      
    for (i in 1:m) {
      Q[i, i] = q[i] * (1 - q[i]);
      for (j in 1:i - 1) {
        Q[i, j] = min([q[i], q[j]]) - q[i] * q[j];
        Q[j, i] = Q[i, j];
      }
    }
  
    return kronecker(N * inverse(G), inverse(Q));
  }
}
data {
  int N;               // Number of observation
  int P;               // Number of predictors
  int K;               // Number of quantiles
  vector[K] q;
  vector[N] y;         
  matrix[N, P] x;
}
transformed data {
  matrix[K * P, K * P] W = make_w(x, q);
}
parameters {
  // can add ordered constraint here
   array[P] vector[K] beta;
   real<lower=0> sigma;
}
model {
  vector[K * P] score_vec = score(q, y, x, beta) / sigma;
  
  for (i in 1:K) 
    beta[, i] ~ normal(0, 4);
  
  sigma ~ exponential(1);
 
  target += -quad_form(W, score_vec) / (2 * N * K) - K * N * log(sigma);

}
```

I'll simulate the same data as in part II:
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
set.seed(12312)
library(quantreg)
N     <- 1000
x     <- runif(N, max=10)
alpha <- -1
beta  <- 2
y     <- alpha + beta * x + rnorm(N, sd = .5 * x)
q     <- c(0.05, 0.5, 0.95)

# frequentist estimate
out_freq <- quantreg::rq(y ~ x, tau = q)

out_score <- multiple_score_qr$sample(
  data = list(N = N,
              P = 2,
              K = length(q),
              q = q,
              y = y,
              x = as.matrix(data.frame(alpha = 1,  x = x))),
  seed = 12123123, 
  parallel_chains = 4,
  iter_warmup = 500,
  iter_sampling = 500,
    refresh = 0,
  show_messages = FALSE
)

out_score$summary()
```
# Test on ImmunogG data

```{r}
library(Brq)
data("ImmunogG")
dat <- data.frame(y = ImmunogG$IgG, 
                  alpha = 1, 
                  x = ImmunogG$Age, 
                  xsq = ImmunogG$Age^2)

out_score_mod <- multiple_score_qr$sample(
  data = list(N = nrow(ImmunogG),
              P = 3,
              K = 3,
              q = c(0.05, 0.5, 0.95),
              y = ImmunogG$IgG,
              x = as.matrix(dat[, 2:4])),
  seed = 12123123, 
  parallel_chains = 4,
  max_treedepth = 12,
  iter_warmup = 500,
  iter_sampling = 500,
    refresh = 0,
  show_messages = FALSE
)

out_freq_1 <- rq(y ~ x + xsq, 
               data = dat,
               tau = 0.05)
out_freq_2 <- rq(y ~ x + xsq, 
               data = dat,
               tau = 0.5)
out_freq_3 <- rq(y ~ x + xsq, 
               data = dat,
               tau = 0.95)

```

## Results

### Modified score:

```{r}
out_score_mod$summary()
```

Quantreg

### Quantreg:

```{r}
summary(out_freq_1, se = "iid")
summary(out_freq_2, se = "iid")
summary(out_freq_3, se = "iid")
```

