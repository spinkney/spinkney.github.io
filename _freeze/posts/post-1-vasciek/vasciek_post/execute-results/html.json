{
  "hash": "ca62b6bd80f081842420856bdfc76e9c",
  "result": {
    "markdown": "---\ntitle: \"Vasicek Quantile Regression in Stan\"\nauthor: \"Sean Pinkney\"\ndate: \"2022-10-14\"\ncategories: [model, stan]\nbibliography: references.bib\ndraft: false\n---\n\n\nIn this post I'll show a way to do quantile regression on a bounded unit interval. The Vasicek distribution is an alternative distribution for beta regressions and is described in @vasicek. The Vasicek distribution is given as\n\n$$\n  \\begin{aligned}\nf(y \\mid \\alpha, \\theta) &= \\sqrt{\\frac{1 - \\theta}{\\theta}} \\exp \\bigg\\{\\frac{1}{2} \\bigg[\\Phi^{-1}(y)^2 - \n                                                                                             \\bigg(\\frac{\\Phi^{-1}(y) \\sqrt{1 - \\theta} - \\Phi^{-1}(\\alpha)}{\\sqrt{\\theta}} \\bigg)^2\n                                                                                           \\bigg\\} \\\\\nF(y \\mid \\alpha, \\theta) &= \\Phi \\bigg( \\frac{\\Phi^{-1}(y) \\sqrt{1 - \\theta} - \\Phi^{-1}(\\alpha)}{\\sqrt{\\theta}} \\bigg) \\\\\nQ(\\tau \\mid \\alpha, \\theta) &= F^{-1}(\\tau \\mid \\alpha, \\theta) = \\Phi \\bigg( \\frac{\\Phi^{-1}(\\alpha) + \\Phi^{-1}(\\tau) \\sqrt{\\theta}}{\\sqrt{1 - \\theta}} \\bigg)\n\\end{aligned}\n$$ where $0 < (y, \\alpha, \\theta, \\tau) < 1$ and $\\Phi$ and $\\Phi^{-1}$ are the standard normal CDF and QF respectively. The mean of the distribution is $\\operatorname{E}(Y) = \\alpha$ and $\\operatorname{Var}(Y) = \\Phi_2(\\Phi^{-1}(\\alpha), \\Phi^{-1}(\\alpha), \\theta)$ where $\\Phi_2$ is the bivariate standard normal CDF.\n\nIn the paper they reparameterize the mean in terms of the $\\tau$-th quantile as $$\n\\alpha = h^{-1}(\\mu) = \\Phi(\\Phi^{-1}(\\mu)\\sqrt{1 - \\theta} - \\Phi^{-1}(\\tau)\\sqrt{\\theta}).\n$$ Given this reparmeterization the log-likelihood is $$\n\\begin{aligned}\n\\ell( \\mu, \\theta \\mid y, \\tau) = \\;& \\frac{n}{2}\\log\\bigg(\\frac{1 - \\theta}{\\theta} \\bigg) - \\frac{\\Phi^{-1}(y)^\\top \\Phi^{-1}(y)}{2} - \\\\\n& \\frac{1}{2\\theta} \\sum_{i=1}^{n} \\bigg(\\sqrt{1 - \\theta}\\bigg[\\Phi^{-1}(y_i) - \\Phi^{-1}(\\mu) \\bigg] + \\sqrt{\\theta}\\Phi^{-1}(\\tau) \\bigg)^2\n\\end{aligned}\n$$ The log-likelihood may be written in Stan as:\n\n``` stan\n  real vasicek_quantile_lpdf(vector y, real theta, vector mu, real tau) {\n    if (tau <= 0 || tau >= 1) \n      reject(\"tau must be between 0 and 1 found tau = \", tau);\n    \n    if (theta <= 0 || theta >= 1) \n      reject(\"theta must be between 0 and 1 found theta = \", theta);\n    \n    int N = num_elements(y);\n    real lpdf = 0.5 * N * (log1m(theta) - log(theta));\n    vector[N] qnorm_mu = inv_Phi(mu);\n    real qnorm_tau = inv_Phi(tau);\n    vector[N] qnorm_y = inv_Phi(y);\n    vector[N] qnorm_alpha = -sqrt(theta) * qnorm_tau + \n                              qnorm_mu * sqrt(1 - theta);\n    \n    return lpdf + 0.5 * dot_self(qnorm_y) -\n            0.5 * sum( (sqrt(1 - theta) * qnorm_y - qnorm_alpha)^2 / theta);\n  }\n```\n\nThe authors provided an R package `vasicekreg` where we can check if it results in the same log-likelihood,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\nlibrary(vasicekreg)\nsource(\"expose_cmdstanr_funs.R\")\nx <- rVASIQ(n = 1, mu = 0.50, sigma = 0.69, tau = 0.50)\nexpose_cmdstanr_functions(\"vasicek.stan\", expose_to_global_env = T)\nstan_lpdf <- vasicek_quantile_lpdf(x, theta = 0.69, mu = 0.5, tau = 0.5)\nr_lpdf <- dVASIQ(x, mu = 0.5, sigma = 0.69, log = T)\nall.equal(stan_lpdf, r_lpdf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nTo expose the Stan function to my R environment I have used the `expose_cmdstanr_funs.R` [script from Rok Češnovar's repo](https://github.com/rok-cesnovar/misc/blob/master/expose-cmdstanr-functions/expose_cmdstanr_functions.R).\n\nWe can test this out aginst the R package fit. The following Stan code performs the regression.\n\nNow, let's see how the package and Stan compare.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 100\nx <- rbinom(n, size = 1, prob = 0.5)\neta <- 0.5 + 1 * x;\nmu <- 1 / (1 + exp(-eta));\nsigma <- 0.5;\ny <- rVASIQ(n, mu, sigma, tau = 0.5)\ndata <- data.frame(y, x, tau = 0.5)\ntau <- 0.5;\nfit_gamlss <- gamlss::gamlss(y ~ x, data = data, family = VASIQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGAMLSS-RS iteration 1: Global Deviance = -55.4043 \nGAMLSS-RS iteration 2: Global Deviance = -55.4042 \n```\n:::\n\n```{.r .cell-code}\nsummary(fit_gamlss)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n******************************************************************\nFamily:  c(\"VASIQ\", \"VasicekQ\") \n\nCall:  gamlss::gamlss(formula = y ~ x, family = VASIQ, data = data) \n\nFitting method: RS() \n\n------------------------------------------------------------------\nMu link function:  logit\nMu Coefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   0.6554     0.1936   3.385  0.00103 **\nx             0.9284     0.2975   3.120  0.00238 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nSigma link function:  logit\nSigma Coefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -0.2929     0.1414  -2.071    0.041 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------------------------------\nNo. of observations in the fit:  100 \nDegrees of Freedom for the fit:  3\n      Residual Deg. of Freedom:  97 \n                      at cycle:  2 \n \nGlobal Deviance:     -55.40424 \n            AIC:     -49.40424 \n            SBC:     -41.58873 \n******************************************************************\n```\n:::\n\n```{.r .cell-code}\nmod <- cmdstan_model(\"vasicek.stan\")\nfit_stan <- mod$sample(\n  data = list(N = n,\n              y = y,\n              x = x,\n              tau = 0.5),\n  refresh = 0,\n  show_messages = FALSE,\n  parallel_chains = 4\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.3 seconds.\n```\n:::\n\n```{.r .cell-code}\nfit_stan$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 10\n  variable   mean median    sd   mad     q5     q95  rhat ess_bulk ess_tail\n  <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n1 lp__     26.2   26.5   1.18  0.957 23.9   27.5     1.00    1981.    2224.\n2 alpha     0.657  0.654 0.198 0.199  0.330  0.985   1.00    2456.    2752.\n3 beta      0.936  0.931 0.296 0.302  0.445  1.42    1.00    2470.    2200.\n4 sigma    -0.263 -0.268 0.141 0.141 -0.483 -0.0209  1.00    2616.    2473.\n```\n:::\n:::\n\n\nSimilar results!\n\nWe can update the code to run multiple quantiles which is the same as running the model for each quantile. In Stan, we can run the same model multiple times or we do the loop, as I show below, inside the program and pass a vector of $\\tau$'s in as data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfittaus <- lapply(c(0.10, 0.25, 0.50, 0.75, 0.90), function(Tau)\n {\n  tau <<- Tau; \n  gamlss::gamlss(y ~ x, data = data, family = VASIQ)\n })\n\ngamlss_mtau <-  sapply(fittaus, function(x) summary(x)[, 1])\n\n\nmod_vector <- cmdstan_model(\"vasciek_vector_tau.stan\")\nfit_stan_vector <- mod_vector$sample(\n  data = list(N = n,\n              y = y,\n              x = x,\n              K = 5,\n              tau = c(0.1,0.25, 0.5, 0.75, 0.9)),\n  refresh = 0,\n  show_messages = FALSE,\n  parallel_chains = 4\n)\n```\n:::\n\n\nThe parameter results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(stan = fit_stan_vector$summary()[-1, 1:2], \n           gamlss_estimates =c(t(gamlss_mtau)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   stan.variable  stan.mean gamlss_estimates\n1       alpha[1] -1.1768928       -1.1439249\n2       alpha[2] -0.2992555       -0.2798790\n3       alpha[3]  0.6571251        0.6553778\n4       alpha[4]  1.6818706        1.6508267\n5       alpha[5]  2.7209694        2.6706897\n6        beta[1]  0.8880346        0.8953157\n7        beta[2]  0.8795350        0.8746433\n8        beta[3]  0.9316846        0.9284407\n9        beta[4]  1.0657726        1.0609815\n10       beta[5]  1.2600745        1.2410836\n11      sigma[1] -0.2602243       -0.2913405\n12      sigma[2] -0.2638038       -0.2927525\n13      sigma[3] -0.2616609       -0.2928563\n14      sigma[4] -0.2575334       -0.2927568\n15      sigma[5] -0.2588908       -0.2914669\n```\n:::\n:::\n\n\n[Aki Veharti](https://twitter.com/avehtari/status/1580841358713323521) correctly noted that the increase in the number of parameters will reduce the step size and increase the number of steps. If you have lots of data then it may make more sense to run each $\\tau$ independently.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindividual_fit <- fit_stan$sampler_diagnostics()[,,c(\"stepsize__\", \n                                                     \"n_leapfrog__\")]\nvector_fit <- fit_stan_vector$sampler_diagnostics()[,,c(\"stepsize__\",\n                                                        \"n_leapfrog__\")]\n\ndata.frame(stepsize_avg = round(c(mean(individual_fit[, , 1]),\n                                  mean(vector_fit[, , 1])), 2),\n           n_leapfrog_avg = round(c(mean(individual_fit[, , 2]), \n                                    mean(vector_fit[, , 2])), 2),\n           row.names = c(\"individual_fit\", \"vector_fit\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               stepsize_avg n_leapfrog_avg\nindividual_fit         0.57           5.84\nvector_fit             0.38          13.10\n```\n:::\n:::\n\n\nWe see that the sampler must take smaller steps and increase the number of leapfrog integrations.\n\nLastly, we can plot the effects. Here are the intercepts and beta coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(posterior)\nlibrary(tidybayes)\nlibrary(ggplot2)\ntheme_set(theme_tidybayes())\n\nfit_stan_vector |>\n  spread_draws(alpha[K]) |>\n  ggplot(aes(y = K, x = alpha))  +\n  stat_slabh()\n```\n\n::: {.cell-output-display}\n![](vasciek_post_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit_stan_vector |>\n  spread_draws(beta[K]) |>\n  ggplot(aes(y = K, x = beta))  +\n  stat_slabh()\n```\n\n::: {.cell-output-display}\n![](vasciek_post_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\nIn my next post, [quantile regression post](/posts/post-1-quantile-reg/quantile-reg.qmd) I'll show various ways to represent a quantile regression in Stan where the outcome, however, is continuous on the real line.\n\n## Appendix\n\nSingle tau\n\n``` stan\nfunctions {\n  real vasicek_quantile_lpdf(vector y, real theta, vector mu, real tau) {\n    int N = num_elements(y);\n    real lpdf = 0.5 * N * (log1m(theta) - log(theta));\n    vector[N] qnorm_mu = inv_Phi(mu);\n    real qnorm_tau = inv_Phi(tau);\n    vector[N] qnorm_y = inv_Phi(y);\n    vector[N] qnorm_alpha = -sqrt(theta) * qnorm_tau + \n                              qnorm_mu * sqrt(1 - theta);\n    \n    return lpdf + 0.5 * dot_self(qnorm_y) - \n            0.5 * sum( (sqrt(1 - theta) * qnorm_y - qnorm_alpha)^2 / theta);\n  }\n}\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n  real<lower=0, upper=1> tau;\n} \nparameters {\n  real alpha;\n  real beta;\n  real sigma;\n} \nmodel {\n  alpha ~ normal(0, 4);\n  beta ~ normal(0, 4);\n  sigma ~ normal(0, 2);\n  y ~ vasicek_quantile(inv_logit(sigma), inv_logit(alpha + beta * x), tau);\n}\n```\n\nMultiple tau\n\n``` stan\nfunctions {\n  real vasicek_quantile_lpdf(vector y, real theta, vector mu, real tau) {\n    if (tau <= 0 || tau >= 1) \n      reject(\"tau must be between 0 and 1 found tau = \", tau);\n    \n    if (theta <= 0 || theta >= 1) \n      reject(\"theta must be between 0 and 1 found theta = \", theta);\n    \n    int N = num_elements(y);\n    real lpdf = 0.5 * N * (log1m(theta) - log(theta));\n    vector[N] qnorm_mu = inv_Phi(mu);\n    real qnorm_tau = inv_Phi(tau);\n    vector[N] qnorm_y = inv_Phi(y);\n    vector[N] qnorm_alpha = -sqrt(theta) * qnorm_tau +  \n                              qnorm_mu * sqrt(1 - theta);\n    \n    return lpdf + \n            0.5 * dot_self(qnorm_y) - \n            0.5 * sum( (sqrt(1 - theta) * qnorm_y - qnorm_alpha)^2 / theta);\n  }\n}\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n  \n  int<lower=1> K;\n  vector<lower=0, upper=1>[K] tau;\n} \nparameters {\n  vector[K] alpha;\n  vector[K] beta;\n  vector[K] sigma;\n} \nmodel {\n  alpha ~ normal(0, 4);\n  beta ~ normal(0, 4);\n  sigma ~ normal(0, 2);\n  \n  for (i in 1:K)\n    y ~ vasicek_quantile(inv_logit(sigma[i]), \n                         inv_logit(alpha[i] + beta[i] * x), tau[i]);\n}\n```\n",
    "supporting": [
      "vasciek_post_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}