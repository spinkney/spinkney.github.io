{
  "hash": "c9cbaaeb9ecf3abbde9cebb92bff4daf",
  "result": {
    "markdown": "---\ntitle: \"Quantile Regressions in Stan: Part III\"\nauthor: \"Sean Pinkney\"\ndate: last-modified\ncategories: [stan, quantile]\nbibliography: references.bib\ndraft: true\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\n---\n\n::: {.cell}\n\n:::\n\n\nThis is part III of the quantile regression series. [Part I](/posts/post-2-quantile-reg-part-I/quantile-reg.qmd) and [part II](/posts/post-2-quantile-reg-part-II/quantile-reg-part-II.qmd) show the Bayesian quantile regression using the asymmetric Laplace distribution, augmented scheme, and score. In this post I'm going to show the multiple quantile regression given in @score, which is a follow up to part II.\n\n\n# Multiple quantile regression with score\n\nThe score method includes the regressors into the objective function as $$\ns_\\tau(\\beta) = \\sum_{i=1}^{n} x_i \\psi_\\tau(y_i - x_i^{\\top}\\beta).\n$$ where $\\psi_\\tau(u) = \\tau - I(u < 0)$.\n\n::: callout-warning\nWarning! It seems that $\\psi$ doesn't work for me! What does work is using $\\rho_\\tau = \\frac{|u| + (2\\tau - 1)u}{2}$ as before. They mention that the loss is the same but then use new notation indicating that it's different. Anyway, this may be what they intended.\n:::\n\n@score consider the following \"working\" likelihood \n$$\n\\mathcal{L}(y \\mid x,\\, \\beta) = C \\exp\\bigg(-\\frac{1}{2n} s_\\tau(\\beta)^{\\top} W s_\\tau(\\beta)  \\bigg),\n$$\nwhere $W$ is a $p \\times p$ positive definite weight matrix, and C is a constant free of $\\beta$. The quadratic form and the given objective function implies that the quantile estimator is maximized at the typical quantile estimate.\n\nThe $W$ matrix for multiple quantiles is given as\n\n$$\nW = (Q \\otimes G )^{-1}, \\text{ where } Q = (\\min(\\tau_i, \\tau_j) - \\tau_i \\tau_j)_{ij}, \\; G = \\frac{1}{n}\\sum_{i=1}^n x_i x_i^{\\top}.\n$$ \n\nA nice property of $W$ is that it depends all on user input data so can be constructed outside of the MCMC iterations.\n\n## Score function\n\nThe following Stan model implements the multiple $\\tau$ code. \n\n\n::: {.cell output.var='multiple_score_qr'}\n\n```{.stan .fold-show .cell-code}\nfunctions{\n  matrix kronecker(matrix A, matrix B) {\n    matrix[rows(A) * rows(B), cols(A) * cols(B)] C;\n    int m = rows(A);\n    int n = cols(A);\n    int p = rows(B);\n    int q = cols(B);\n    for (i in 1:m) {\n      for (j in 1:n) {\n        int row_start = (i - 1) * p + 1;\n        int row_end = (i - 1) * p + p;\n        int col_start = (j - 1) * q + 1;\n        int col_end = (j - 1) * q + q;\n        C[row_start:row_end, col_start:col_end] = A[i, j] * B;\n      }\n    }\n   return C;\n}\n  \n  vector q_loss(real q, vector u){\n    return (abs(u) + (2 * q - 1) * u);\n }\n    \n  vector score(vector q, vector y, matrix x, array[] vector beta) {\n    int N = num_elements(y);\n    int P = num_elements(beta[ , 1]);\n    int K = num_elements(q);\n    matrix[K, P] out;\n      \n    for (k in 1:K) {\n      out[k] = (x' * q_loss(q[k], y - x * to_vector(beta[ ,k])))';\n    }\n      \n    return to_vector(out);\n  }\n    \n  matrix make_w (matrix x, vector q) {\n    int N = rows(x);\n    int P = cols(x);\n    int m = num_elements(q);\n    matrix[m * P, m * P] out;\n      \n    matrix[m, m] Q;\n    matrix[P, P] G = crossprod(x) ;\n    \n    G[1:P, 1] /= log(N);\n    G[1, 2:P] = transpose(G[2:P, 1]);\n      \n    for (i in 1:m) {\n      Q[i, i] = q[i] * (1 - q[i]);\n      for (j in 1:i - 1) {\n        Q[i, j] = min([q[i], q[j]]) - q[i] * q[j];\n        Q[j, i] = Q[i, j];\n      }\n    }\n  \n    return kronecker(N * inverse(G), inverse(Q));\n  }\n}\ndata {\n  int N;               // Number of observation\n  int P;               // Number of predictors\n  int K;               // Number of quantiles\n  vector[K] q;\n  vector[N] y;         \n  matrix[N, P] x;\n}\ntransformed data {\n  matrix[K * P, K * P] W = make_w(x, q);\n}\nparameters {\n  // can add ordered constraint here\n   array[P] vector[K] beta;\n}\nmodel {\n  vector[K * P] score_vec = score(q, y, x, beta);\n  \n  for (i in 1:K) \n    beta[, i] ~ normal(0, 4);\n \n  target += -quad_form(W, score_vec) / (2 * N);\n\n}\n```\n:::\n\n\nI'll simulate the same data as in part II:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nset.seed(12312)\nlibrary(quantreg)\nN     <- 1000\nx     <- runif(N, max=10)\nalpha <- -1\nbeta  <- 2\ny     <- alpha + beta * x + rnorm(N, sd = .5 * x)\nq     <- c(0.05, 0.5, 0.95)\n\n# frequentist estimate\nout_freq <- quantreg::rq(y ~ x, tau = q)\n\nout_score <- multiple_score_qr$sample(\n  data = list(N = N,\n              P = 2,\n              K = length(q),\n              q = q,\n              y = y,\n              x = as.matrix(data.frame(alpha = 1, x = x))),\n  seed = 12123123, \n  parallel_chains = 4,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 2.2 seconds.\nChain 2 finished in 2.5 seconds.\nChain 3 finished in 2.4 seconds.\nChain 4 finished in 2.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.4 seconds.\nTotal execution time: 2.6 seconds.\n```\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\nout_score$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 10\n  variable        mean   median      sd     mad       q5      q95  rhat ess_bulk\n  <chr>          <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n1 lp__      -68545.    -6.85e+4 1.73    1.63    -6.85e+4 -6.85e+4  1.00     670.\n2 beta[1,1]     -1.03  -1.03e+0 0.0226  0.0225  -1.06e+0 -9.89e-1  1.00     629.\n3 beta[2,1]      1.23   1.23e+0 0.00426 0.00440  1.23e+0  1.24e+0  1.00     726.\n4 beta[1,2]     -0.965 -9.66e-1 0.00910 0.00902 -9.79e-1 -9.49e-1  1.01     767.\n5 beta[2,2]      1.99   1.99e+0 0.00208 0.00206  1.99e+0  1.99e+0  1.00     983.\n6 beta[1,3]     -0.987 -9.89e-1 0.0129  0.0127  -1.00e+0 -9.63e-1  1.01     566.\n7 beta[2,3]      2.85   2.85e+0 0.00718 0.00717  2.84e+0  2.86e+0  1.00     653.\n# … with 1 more variable: ess_tail <dbl>\n```\n:::\n:::\n\n# Test on ImmunogG data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Brq)\ndata(\"ImmunogG\")\ndat <- data.frame(y = ImmunogG$IgG, \n                  alpha = 1, \n                  x = ImmunogG$Age, \n                  xsq = ImmunogG$Age^2)\n\nout_score_mod <- multiple_score_qr$sample(\n  data = list(N = nrow(ImmunogG),\n              P = 3,\n              K = 3,\n              q = c(0.05, 0.5, 0.95),\n              y = ImmunogG$IgG,\n              x = as.matrix(dat[, 2:4])),\n  seed = 12123123, \n  parallel_chains = 4,\n  max_treedepth = 12,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 12.2 seconds.\nChain 2 finished in 12.1 seconds.\nChain 4 finished in 18.2 seconds.\nChain 3 finished in 19.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 15.5 seconds.\nTotal execution time: 19.4 seconds.\n```\n:::\n\n```{.r .cell-code}\nout_freq_1 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.05)\nout_freq_2 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.5)\nout_freq_3 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.95)\n```\n:::\n\n\n## Results\n\n### Modified score:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout_score_mod$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 10\n   variable       mean   median      sd     mad       q5      q95  rhat ess_bulk\n   <chr>         <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__       -1.03e+4 -1.03e+4 2.39    2.22    -1.03e+4 -1.03e+4  1.00     529.\n 2 beta[1,1]   7.24e-1  7.37e-1 0.0828  0.0659   5.73e-1  8.39e-1  1.01     478.\n 3 beta[2,1]   1.22e+0  1.22e+0 0.0589  0.0525   1.14e+0  1.32e+0  1.01     465.\n 4 beta[3,1]  -1.39e-1 -1.38e-1 0.00865 0.00807 -1.54e-1 -1.26e-1  1.01     482.\n 5 beta[1,2]   2.70e+0  2.71e+0 0.101   0.116    2.53e+0  2.85e+0  1.01     570.\n 6 beta[2,2]   1.20e+0  1.20e+0 0.0615  0.0654   1.10e+0  1.30e+0  1.01     549.\n 7 beta[3,2]  -7.91e-2 -7.89e-2 0.00834 0.00842 -9.24e-2 -6.55e-2  1.00     580.\n 8 beta[1,3]   7.37e+0  7.34e+0 0.133   0.125    7.19e+0  7.62e+0  1.01     367.\n 9 beta[2,3]  -6.03e-1 -5.91e-1 0.110   0.107   -7.97e-1 -4.42e-1  1.01     349.\n10 beta[3,3]   2.71e-1  2.71e-1 0.0195  0.0192   2.41e-1  3.05e-1  1.01     373.\n# … with 1 more variable: ess_tail <dbl>\n```\n:::\n:::\n\n\nQuantreg\n\n### Quantreg:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(out_freq_1, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.05, data = dat)\n\ntau: [1] 0.05\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  0.76514  0.41470    1.84507  0.06603\nx            1.19143  0.46444    2.56528  0.01080\nxsq         -0.13371  0.08304   -1.61021  0.10842\n```\n:::\n\n```{.r .cell-code}\nsummary(out_freq_2, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.5, data = dat)\n\ntau: [1] 0.5\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  2.80112  0.64149    4.36659  0.00002\nx            1.15865  0.53747    2.15577  0.03191\nxsq         -0.07523  0.09148   -0.82239  0.41152\n```\n:::\n\n```{.r .cell-code}\nsummary(out_freq_3, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.95, data = dat)\n\ntau: [1] 0.95\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  7.23563  1.36934    5.28402  0.00000\nx           -0.48165  1.24816   -0.38589  0.69986\nxsq          0.24602  0.20422    1.20469  0.22929\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}