{
  "hash": "58ea9aa68bfb545d233044f2bbf46f64",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Quantile Regressions in Stan: Part III\"\nauthor: \"Sean Pinkney\"\ndate: \"2022-10-23\"\ncategories: [stan, quantile]\nbibliography: references.bib\ndraft: false\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\n---\n\n\n::: {.cell}\n\n:::\n\n\nThis is part III of the quantile regression series. [Part I](/posts/post-2-quantile-reg-series/post-2-quantile-reg-part-I/quantile-reg.html) and [part II](/posts/post-2-quantile-reg-series/post-2-quantile-reg-part-II/quantile-reg-part-II.html) show the Bayesian quantile regression using the asymmetric Laplace distribution, augmented scheme, and score. In this post I'm going to show the multiple quantile regression given in @score, which is a follow up to part II.\n\n\n# Multiple quantile regression with score\n\nThe score method includes the regressors into the objective function as $$\ns_\\tau(\\beta) = \\sum_{i=1}^{n} x_i \\psi_\\tau(y_i - x_i^{\\top}\\beta).\n$$ where $\\psi_\\tau(u) = \\tau - I(u < 0)$.\n\n@score consider the following \"working\" likelihood \n$$\n\\mathcal{L}(y \\mid x,\\, \\beta) = C \\exp\\bigg(-\\frac{1}{2n} s_\\tau(\\beta)^{\\top} W s_\\tau(\\beta)  \\bigg),\n$$\nwhere $W$ is a $p \\times p$ positive definite weight matrix, and C is a constant free of $\\beta$. The quadratic form and the given objective function implies that the quantile estimator is maximized at the typical quantile estimate.\n\nThe $W$ matrix for multiple quantiles is given as\n\n$$\nW = (Q \\otimes G )^{-1}, \\text{ where } Q = (\\min(\\tau_i, \\tau_j) - \\tau_i \\tau_j)_{ij}, \\; G = \\frac{1}{n}\\sum_{i=1}^n x_i x_i^{\\top}.\n$$ \n\nA nice property of $W$ is that it depends all on user input data so can be constructed outside of the MCMC iterations.\n\n## Score function\n\nThe following Stan model implements the multiple $\\tau$ code. \n\n\n::: {.cell output.var='multiple_score_qr'}\n\n```{.stan .fold-show .cell-code}\nfunctions{\n  matrix kronecker(matrix A, matrix B) {\n    matrix[rows(A) * rows(B), cols(A) * cols(B)] C;\n    int m = rows(A);\n    int n = cols(A);\n    int p = rows(B);\n    int q = cols(B);\n    for (i in 1:m) {\n      for (j in 1:n) {\n        int row_start = (i - 1) * p + 1;\n        int row_end = (i - 1) * p + p;\n        int col_start = (j - 1) * q + 1;\n        int col_end = (j - 1) * q + q;\n        C[row_start:row_end, col_start:col_end] = A[i, j] * B;\n      }\n    }\n   return C;\n}\n  \n  vector q_loss(real q, vector u){\n    return (abs(u) + (2 * q - 1) * u);\n }\n    \n  vector score(vector q, vector y, matrix x, array[] vector beta) {\n    int N = num_elements(y);\n    int P = num_elements(beta[ , 1]);\n    int K = num_elements(q);\n    matrix[K, P] out;\n      \n    for (k in 1:K) {\n      out[k] = transpose(transpose(x) * q_loss(q[k], y - x * to_vector(beta[ ,k])));\n    }\n      \n    return to_vector(out);\n  }\n    \n  matrix make_w (matrix x, vector q) {\n    int N = rows(x);\n    int P = cols(x);\n    int m = num_elements(q);\n    matrix[m * P, m * P] out;\n      \n    matrix[m, m] Q;\n    matrix[P, P] G = crossprod(x) ;\n    \n  //  G[1:P, 1] /= log(N);\n  //  G[1, 2:P] = transpose(G[2:P, 1]);\n      \n    for (i in 1:m) {\n      Q[i, i] = q[i] * (1 - q[i]);\n      for (j in 1:i - 1) {\n        Q[i, j] = min([q[i], q[j]]) - q[i] * q[j];\n        Q[j, i] = Q[i, j];\n      }\n    }\n  \n    return kronecker(N * inverse(G), inverse(Q));\n  }\n}\ndata {\n  int N;               // Number of observation\n  int P;               // Number of predictors\n  int K;               // Number of quantiles\n  vector[K] q;\n  vector[N] y;         \n  matrix[N, P] x;\n}\ntransformed data {\n  matrix[K * P, K * P] W = make_w(x, q);\n}\nparameters {\n  // can add ordered constraint here\n   array[P] vector[K] beta;\n   real<lower=0> sigma;\n}\nmodel {\n  vector[K * P] score_vec = score(q, y, x, beta) / sigma;\n  \n  for (i in 1:K) \n    beta[, i] ~ normal(0, 4);\n  \n  sigma ~ exponential(1);\n \n  target += -quad_form(W, score_vec) / (2 * N * K) - K * N * log(sigma);\n\n}\n```\n:::\n\n\nI'll simulate the same data as in part II:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nset.seed(12312)\nlibrary(quantreg)\nN     <- 1000\nx     <- runif(N, max=10)\nalpha <- -1\nbeta  <- 2\ny     <- alpha + beta * x + rnorm(N, sd = .5 * x)\nq     <- c(0.05, 0.5, 0.95)\n\n# frequentist estimate\nout_freq <- quantreg::rq(y ~ x, tau = q)\n\nout_score <- multiple_score_qr$sample(\n  data = list(N = N,\n              P = 2,\n              K = length(q),\n              q = q,\n              y = y,\n              x = as.matrix(data.frame(alpha = 1,  x = x))),\n  seed = 12123123, \n  parallel_chains = 4,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE,\n  show_exceptions = FALSE\n)\n\nout_score$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 10\n  variable       mean    median     sd    mad       q5       q95  rhat ess_bulk\n  <chr>         <dbl>     <dbl>  <dbl>  <dbl>    <dbl>     <dbl> <dbl>    <dbl>\n1 lp__      -3083.    -3083.    1.83   1.67   -3087.   -3081.     1.01     762.\n2 beta[1,1]    -1.39     -1.38  0.266  0.279     -1.83    -0.973  1.00     870.\n3 beta[2,1]     1.30      1.30  0.0417 0.0434     1.23     1.37   1.00     863.\n4 beta[1,2]    -0.862    -0.861 0.122  0.123     -1.06    -0.660  1.01    1135.\n5 beta[2,2]     1.97      1.97  0.0204 0.0202     1.94     2.00   1.00    1095.\n6 beta[1,3]    -0.903    -0.934 0.220  0.213     -1.20    -0.502  1.00    1046.\n7 beta[2,3]     2.83      2.83  0.0462 0.0450     2.75     2.90   1.00    1110.\n8 sigma         1.69      1.69  0.0220 0.0205     1.66     1.73   1.00    1548.\n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n:::\n\n# Test on ImmunogG data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Brq)\ndata(\"ImmunogG\")\ndat <- data.frame(y = ImmunogG$IgG, \n                  alpha = 1, \n                  x = ImmunogG$Age, \n                  xsq = ImmunogG$Age^2)\n\nout_score_mod <- multiple_score_qr$sample(\n  data = list(N = nrow(ImmunogG),\n              P = 3,\n              K = 3,\n              q = c(0.05, 0.5, 0.95),\n              y = ImmunogG$IgG,\n              x = as.matrix(dat[, 2:4])),\n  seed = 12123123, \n  parallel_chains = 4,\n  max_treedepth = 12,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE,\n  show_exceptions = FALSE\n)\n\nout_freq_1 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.05)\nout_freq_2 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.5)\nout_freq_3 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.95)\n```\n:::\n\n\n## Results\n\n### Modified score:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout_score_mod$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 10\n   variable       mean    median     sd    mad        q5      q95  rhat ess_bulk\n   <chr>         <dbl>     <dbl>  <dbl>  <dbl>     <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__      -605.     -605.     2.31   2.12   -609.     -6.02e+2  1.01     632.\n 2 beta[1,1]    0.668     0.688  0.401  0.418    -0.0334  1.26e+0  1.00     683.\n 3 beta[2,1]    1.19      1.19   0.346  0.329     0.623   1.76e+0  1.00     596.\n 4 beta[3,1]   -0.137    -0.137  0.0580 0.0551   -0.235  -4.26e-2  1.00     648.\n 5 beta[1,2]    2.72      2.70   0.318  0.324     2.23    3.26e+0  1.00     706.\n 6 beta[2,2]    1.18      1.19   0.238  0.227     0.779   1.55e+0  1.01     690.\n 7 beta[3,2]   -0.0732   -0.0760 0.0377 0.0361   -0.132  -8.66e-3  1.01     747.\n 8 beta[1,3]    7.20      7.21   0.626  0.613     6.14    8.25e+0  1.00     630.\n 9 beta[2,3]   -0.444    -0.461  0.503  0.478    -1.21    4.21e-1  1.01     597.\n10 beta[3,3]    0.246     0.248  0.0806 0.0752    0.106   3.71e-1  1.00     611.\n11 sigma        1.19      1.19   0.0267 0.0267    1.15    1.23e+0  1.00    1463.\n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n:::\n\n\nQuantreg\n\n### Quantreg:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(out_freq_1, se = \"iid\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.05, data = dat)\n\ntau: [1] 0.05\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  0.76514  0.30477    2.51058  0.01259\nx            1.19143  0.24792    4.80577  0.00000\nxsq         -0.13371  0.04037   -3.31187  0.00104\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(out_freq_2, se = \"iid\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.5, data = dat)\n\ntau: [1] 0.5\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  2.80112  0.59354    4.71936  0.00000\nx            1.15865  0.48282    2.39976  0.01703\nxsq         -0.07523  0.07863   -0.95677  0.33947\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(out_freq_3, se = \"iid\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.95, data = dat)\n\ntau: [1] 0.95\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  7.23563  0.67142   10.77659  0.00000\nx           -0.48165  0.54617   -0.88186  0.37857\nxsq          0.24602  0.08895    2.76597  0.00603\n```\n\n\n:::\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}