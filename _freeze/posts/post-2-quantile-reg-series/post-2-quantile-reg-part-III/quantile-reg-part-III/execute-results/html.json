{
  "hash": "5785a747735b6489a93b6ea2c36486f6",
  "result": {
    "markdown": "---\ntitle: \"Quantile Regressions in Stan: Part III\"\nauthor: \"Sean Pinkney\"\ndate: last-modified\ncategories: [stan, quantile]\nbibliography: references.bib\ndraft: true\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\n---\n\n::: {.cell}\n\n:::\n\n\nThis is part III of the quantile regression series. [Part I](/posts/post-2-quantile-reg-part-I/quantile-reg.qmd) and [part II](/posts/post-2-quantile-reg-part-II/quantile-reg-part-II.qmd) show the Bayesian quantile regression using the asymmetric Laplace distribution, augmented scheme, and score. In this post I'm going to show the multiple quantile regression given in @score, which is a follow up to part II.\n\n\n# Multiple quantile regression with score\n\nThe score method includes the regressors into the objective function as $$\ns_\\tau(\\beta) = \\sum_{i=1}^{n} x_i \\psi_\\tau(y_i - x_i^{\\top}\\beta).\n$$ where $\\psi_\\tau(u) = \\tau - I(u < 0)$.\n\n::: callout-warning\nWarning! It seems that $\\psi$ doesn't work for me! What does work is using $\\rho_\\tau = \\frac{|u| + (2\\tau - 1)u}{2}$ as before. They mention that the loss is the same but then use new notation indicating that it's different. Anyway, this may be what they intended.\n:::\n\n@score consider the following \"working\" likelihood \n$$\n\\mathcal{L}(y \\mid x,\\, \\beta) = C \\exp\\bigg(-\\frac{1}{2n} s_\\tau(\\beta)^{\\top} W s_\\tau(\\beta)  \\bigg),\n$$\nwhere $W$ is a $p \\times p$ positive definite weight matrix, and C is a constant free of $\\beta$. The quadratic form and the given objective function implies that the quantile estimator is maximized at the typical quantile estimate.\n\nThe $W$ matrix for multiple quantiles is given as\n\n$$\nW = (Q \\otimes G )^{-1}, \\text{ where } Q = (\\min(\\tau_i, \\tau_j) - \\tau_i \\tau_j)_{ij}, \\; G = \\frac{1}{n}\\sum_{i=1}^n x_i x_i^{\\top}.\n$$ \n\nA nice property of $W$ is that it depends all on user input data so can be constructed outside of the MCMC iterations.\n\n## Score function\n\nThe following Stan model implements the multiple $\\tau$ code. \n\n\n::: {.cell output.var='multiple_score_qr'}\n\n```{.stan .fold-show .cell-code}\nfunctions{\n  matrix kronecker(matrix A, matrix B) {\n    matrix[rows(A) * rows(B), cols(A) * cols(B)] C;\n    int m = rows(A);\n    int n = cols(A);\n    int p = rows(B);\n    int q = cols(B);\n    for (i in 1:m) {\n      for (j in 1:n) {\n        int row_start = (i - 1) * p + 1;\n        int row_end = (i - 1) * p + p;\n        int col_start = (j - 1) * q + 1;\n        int col_end = (j - 1) * q + q;\n        C[row_start:row_end, col_start:col_end] = A[i, j] * B;\n      }\n    }\n   return C;\n}\n  \n  vector q_loss(real q, vector u){\n    return (abs(u) + (2 * q - 1) * u);\n }\n    \n  matrix score(vector q, vector y, matrix x, array[] vector beta) {\n    int N = num_elements(y);\n    int P = num_elements(beta[ , 1]);\n    int K = num_elements(q);\n    matrix[K, P] out;\n      \n    for (k in 1:K) {\n      out[k] = (x' * q_loss(q[k], y - x * to_vector(beta[ ,k])))';\n    }\n      \n    return out;\n  }\n    \n  matrix make_w (matrix x, vector q) {\n    int N = rows(x);\n    int P = cols(x);\n    int m = num_elements(q);\n    matrix[m * P, m * P] out;\n      \n    matrix[m, m] Q;\n    matrix[P, P] G = crossprod(x) / N ;\n      \n    for (i in 1:m) {\n      Q[i, i] = q[i] * (1 - q[i]);\n      for (j in 1:i - 1) {\n        Q[i, j] = min([q[i], q[j]]) - q[i] * q[j];\n        Q[j, i] = Q[i, j];\n      }\n    }\n  \n    return kronecker(inverse(G), inverse(Q));\n  }\n}\ndata {\n  int N;               // Number of observation\n  int P;               // Number of predictors\n  int K;               // Number of quantiles\n  vector[K] q;\n  vector[N] y;         \n  matrix[N, P] x;\n}\ntransformed data {\n  matrix[K * P, K * P] W = make_w(x, q);\n}\nparameters {\n  // can add ordered constraint here\n   array[P] vector[K] beta;\n}\nmodel {\n  vector[K * P] score_vec = to_vector(score(q, y, x, beta));\n  \n  for (i in 1:K) \n    beta[, i] ~ normal(0, 4);\n \n  target += -quad_form(W, score_vec) / (2 * N);\n\n}\n```\n:::\n\n\nI'll simulate the same data as in part II:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nset.seed(12312)\nlibrary(quantreg)\nN     <- 1000\nx     <- runif(N, max=10)\nalpha <- -1\nbeta  <- 2\ny     <- alpha + beta * x + rnorm(N, sd = .5 * x)\nq     <- c(0.05, 0.5, 0.95)\n\n# frequentist estimate\nout_freq <- quantreg::rq(y ~ x, tau = q)\n\nout_score <- multiple_score_qr$sample(\n  data = list(N = N,\n              P = 2,\n              K = length(q),\n              q = q,\n              y = y,\n              x = as.matrix(data.frame(alpha = 1, x = x))),\n  seed = 12123123, \n  parallel_chains = 4,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 2 finished in 2.2 seconds.\nChain 4 finished in 2.7 seconds.\nChain 1 finished in 2.8 seconds.\nChain 3 finished in 2.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.6 seconds.\nTotal execution time: 2.9 seconds.\n```\n:::\n\n```{.r .cell-code  code-fold=\"show\"}\nout_score$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 10\n  variable        mean   median      sd     mad       q5      q95  rhat ess_bulk\n  <chr>          <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n1 lp__      -12888.    -1.29e+4 1.85    1.63    -1.29e+4 -1.29e+4  1.01     691.\n2 beta[1,1]     -1.38  -1.37e+0 0.107   0.0971  -1.59e+0 -1.22e+0  1.01     522.\n3 beta[2,1]      1.30   1.29e+0 0.0176  0.0168   1.27e+0  1.33e+0  1.01     563.\n4 beta[1,2]     -0.867 -8.65e-1 0.0408  0.0440  -9.33e-1 -8.02e-1  1.00     805.\n5 beta[2,2]      1.97   1.97e+0 0.00638 0.00683  1.96e+0  1.98e+0  1.00     794.\n6 beta[1,3]     -1.02  -1.02e+0 0.0701  0.0712  -1.13e+0 -8.92e-1  1.00     810.\n7 beta[2,3]      2.86   2.86e+0 0.0171  0.0171   2.83e+0  2.88e+0  1.00     774.\n# … with 1 more variable: ess_tail <dbl>\n```\n:::\n:::\n\n# Test on ImmunogG data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Brq)\ndata(\"ImmunogG\")\ndat <- data.frame(y = ImmunogG$IgG, \n                  alpha = 1, \n                  x = ImmunogG$Age, \n                  xsq = ImmunogG$Age^2)\n\nout_score_mod <- multiple_score_qr$sample(\n  data = list(N = nrow(ImmunogG),\n              P = 3,\n              K = 3,\n              q = c(0.05, 0.5, 0.95),\n              y = ImmunogG$IgG,\n              x = as.matrix(dat[, 2:4])),\n  seed = 12123123, \n  parallel_chains = 4,\n  iter_warmup = 500,\n  iter_sampling = 500,\n    refresh = 0,\n  show_messages = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 2 finished in 7.7 seconds.\nChain 3 finished in 7.8 seconds.\nChain 1 finished in 8.3 seconds.\nChain 4 finished in 8.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 8.0 seconds.\nTotal execution time: 8.3 seconds.\n```\n:::\n\n```{.r .cell-code}\nout_freq_1 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.05)\nout_freq_2 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.5)\nout_freq_3 <- rq(y ~ x + xsq, \n               data = dat,\n               tau = 0.95)\n```\n:::\n\n\n## Results\n\n### Modified score:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout_score_mod$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 10\n   variable        mean    median     sd    mad       q5      q95  rhat ess_bulk\n   <chr>          <dbl>     <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__      -1881.      -1.88e+3 2.35   2.13   -1.89e+3 -1.88e+3  1.00     586.\n 2 beta[1,1]     0.727    7.52e-1 0.221  0.229   3.33e-1  1.05e+0  1.01     628.\n 3 beta[2,1]     1.19     1.18e+0 0.163  0.154   9.45e-1  1.47e+0  1.01     563.\n 4 beta[3,1]    -0.136   -1.35e-1 0.0252 0.0237 -1.79e-1 -9.81e-2  1.00     605.\n 5 beta[1,2]     2.65     2.64e+0 0.169  0.165   2.39e+0  2.94e+0  1.01     652.\n 6 beta[2,2]     1.23     1.23e+0 0.122  0.115   1.01e+0  1.41e+0  1.01     606.\n 7 beta[3,2]    -0.0807  -8.22e-2 0.0189 0.0178 -1.10e-1 -4.81e-2  1.01     635.\n 8 beta[1,3]     7.36     7.37e+0 0.290  0.274   6.86e+0  7.81e+0  1.00     536.\n 9 beta[2,3]    -0.610   -6.17e-1 0.227  0.220  -9.62e-1 -2.25e-1  1.00     503.\n10 beta[3,3]     0.274    2.75e-1 0.0365 0.0360  2.11e-1  3.30e-1  1.00     511.\n# … with 1 more variable: ess_tail <dbl>\n```\n:::\n:::\n\n\nQuantreg\n\n### Quantreg:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(out_freq_1, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.05, data = dat)\n\ntau: [1] 0.05\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  0.76514  0.41470    1.84507  0.06603\nx            1.19143  0.46444    2.56528  0.01080\nxsq         -0.13371  0.08304   -1.61021  0.10842\n```\n:::\n\n```{.r .cell-code}\nsummary(out_freq_2, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.5, data = dat)\n\ntau: [1] 0.5\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  2.80112  0.64149    4.36659  0.00002\nx            1.15865  0.53747    2.15577  0.03191\nxsq         -0.07523  0.09148   -0.82239  0.41152\n```\n:::\n\n```{.r .cell-code}\nsummary(out_freq_3, se = \"boot\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall: rq(formula = y ~ x + xsq, tau = 0.95, data = dat)\n\ntau: [1] 0.95\n\nCoefficients:\n            Value    Std. Error t value  Pr(>|t|)\n(Intercept)  7.23563  1.36934    5.28402  0.00000\nx           -0.48165  1.24816   -0.38589  0.69986\nxsq          0.24602  0.20422    1.20469  0.22929\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}